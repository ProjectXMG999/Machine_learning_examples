{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObgw9V7PZFb7hrWjvz7V7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProjectXMG999/Machine_learning_examples/blob/main/ALGORYTMY_DYNAMICZNE_DOBIERANIE_POZIOM%C3%93W.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARCHITEKTURA:\n",
        "\n",
        "wejście:\n",
        "- aktualny poziom\n",
        "- ista tematów\n",
        "- ostatnie 8 rozmów - podział punktowy na błędy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dane:\n",
        "\n",
        "Temat Poziom\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sgIM1ZuYHk-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input:\n",
        "\n",
        "1. Aktualny Poziom\n",
        "2. Błędy/punkty\n",
        "\n",
        "\n",
        "\n",
        "Output:\n",
        "\n",
        "25 tematów każdy z osobnym prawdopodobieństwem\n",
        "\n",
        "------------------\n",
        "\n",
        "\n",
        "\n",
        "a1, a2, b1, b2, c1, c2 = 6 poziomów\n",
        "\n",
        "prawdopodobientwo tego samgo poziomu = 62%\n",
        "prwdp poziomu 1 do góry/dół = 20%\n",
        "prwdp poziomu 2 do góry/dół = 8%\n",
        "prwdp poziomu 3 do góry/dół = 5%\n",
        "prwdp poziomu 4 do góry/dół = 2%\n",
        "prwdp poziomu 5 do góry/dół = 1%\n",
        "\n",
        "\n",
        "prawdopodobientwo na podstawie:\n",
        "- błędy\n",
        "\n",
        "\n",
        "ilość wystąpień podczas ostatnich 6 rozmów - każde wystąpienie obniża prawdopodobieńwo tematu\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fU62yVPxL7KG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. użytkownik zaczyna grać -> gra 5 rund poczatkowych\n",
        "2. po 5 rundzie wchodzi algorytm\n",
        "3. wyciągamy poziom aktualny\n",
        "4. obliczamy błędy - 2 wersje:\n",
        "  - obliczamy błędy z ostatnich np 5 rund ( mało dynamiczne - jesli 5 ostatnich rund bedzie słaba np - 30, to nowa runda lepsza bedzie delikatnie zmieniać wynik.)\n",
        "  - obliczamy błędy jedynie z ostatniej rundy (duża dynamiczność ae troche niesprawiedliwie)\n",
        "\n",
        "\n",
        "wynik to liczba =<0\n",
        "\n",
        "Jak ten wynik powinien wpływać na wybór tematów?\n",
        "- im większa liczba ujemna, tym powinna być mniejsza szansa na trafienie tematu z poziomu wyżej/ wyższa z dolnego.\n",
        "\n",
        "a1, a2, b1, b2, c1, c2 = 6 poziomów\n",
        "\n",
        "\n",
        "- moze rozroznimy pewna granice? trzymanie sie ponad -10 daje zyskiwanie procentowe w góre/ poniezej powieksza prcentowanie w dół.\n",
        "\n",
        "- w takim razie wartości procentowe poniżej odpowiadają wynikowi:\n",
        "\n",
        "<= 9\n",
        "\n",
        "  - prawdopodobientwo tego samgo poziomu = 62%\n",
        "  - prwdp poziomu 1 do góry = 20%\n",
        "  - prwdp poziomu 2 do góry = 8%\n",
        "  - prwdp poziomu 3 do góry = 5%\n",
        "  - prwdp poziomu 4 do góry = 2%\n",
        "  - prwdp poziomu 5 do góry = 1%\n",
        "\n",
        "= 10\n",
        "\n",
        "  - prawdopodobientwo tego samgo poziomu = 72%\n",
        "  - prwdp poziomu 1 do góry = 10%\n",
        "  - prwdp poziomu 1 w dół = 10%\n",
        "  - prwdp poziomu 2 do góry = 4%\n",
        "  - prwdp poziomu 2 w dół = 4%\n",
        "\n",
        ">= -11\n",
        "\n",
        "  - prawdopodobientwo tego samgo poziomu = 62%\n",
        "  - prwdp poziomu 1 w dół = 20%\n",
        "  - prwdp poziomu 2 w dół = 8%\n",
        "  - prwdp poziomu 3 w dół = 5%\n",
        "  - prwdp poziomu 4 w dół = 2%\n",
        "  - prwdp poziomu 5 w dół = 1%\n",
        "  \n",
        "\n",
        "\n",
        "- jesli brak poziomów w dół = suma procentów poziomów brakujących zostanie rozdana po poziomach pozostałych proporcjonalnie do ich procentów.\n",
        "\n",
        "uzytkownik jest na poziomie c1:\n",
        "statystyki = -1, -3, -6 ,0, -9\n",
        "temat ostatnie = c1a,c1b,c1d,c1c,c1a\n",
        "\n",
        "moja wersja)\n",
        "\n",
        "  1. Pomijamy narazie tematy ostatnie\n",
        "  2. bierzemy jedynie poziom aktualny oraz sume błędów\n",
        "  3. na naszym gotowym schemacie poczatkowego prawdopodobieńtwa tematów kalkulujemy zmiany proporcjonalnie do wyniku sumy błędów użytkowika\n",
        "  4. na wybranym poziomie rozdajemy prawdopodobienstwo na podstawie statnich tematów.\n",
        "   \n",
        "\n",
        "\n",
        "musimy miec jakis maks tych bledow\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1g2ChQhaaQ5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "poziom aktualny a2\n",
        "\n",
        "linia regresji"
      ],
      "metadata": {
        "id": "DHk3TzewDRKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "user:\n",
        "\n",
        "1. b2 podroze\n",
        "2. b2 gotowanie\n",
        "3. b1 sport\n",
        "4. b2 jedzenie\n",
        "5. b1 podróze\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "=\n",
        "\n",
        "dzielac"
      ],
      "metadata": {
        "id": "hz6yDlIpsTDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cel - ustalenie rozkładu prawdopodobieństwa poziomu nastepnego po 20 turach uzytkownika\n",
        "\n",
        "input:\n",
        "- poziom aktualny\n",
        "- suma/średnia błędów z ostatnich 20 tur\n",
        "\n",
        "poziom aktualny --> wektor błędów -->\n",
        "\n",
        "\n",
        "Output:\n",
        "- 6 klas ?\n",
        "\n",
        "\n",
        "Moze jak po prostu rangi w Csie?\n",
        "\n",
        "\n",
        "Jaki to ma sens kurwa?\n",
        "\n",
        "1,0,0,3,0,2,3,0,0,0,2,3\n",
        "\n",
        "uzytkownik jest na b2\n",
        "\n",
        "\n",
        "czyli mamy k\n"
      ],
      "metadata": {
        "id": "lnK0I7SESLC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Materiały:\n",
        "\n",
        "\n",
        "- Zastanów się czy można metodą schodzenia po gradiencie, gdzie gradientem jest np średnia (może być ważona) błędów z każdego poziomu w ostatnich no 10 rozmowach https://en.m.wikipedia.org/wiki/Gradient_descent\n",
        "Nie ma funkcji celu nadal wiem…\n",
        "Może da się jakąś wyznaczyć\n",
        "Może bez sensu. Można wziąć tą średnią z błędów na każdym poziomie i wyliczyć z tego rozkład procentowy i połączyć z wyjściowym rozkładem dla poziomów\n",
        "\n",
        "\n",
        "- https://math.stackexchange.com/questions/87851/combining-two-probability-distributions\n",
        "Można też na podstawie błędów wyznaczy mówię ten średni błąd w ostatnich turach, to sprowadzić do rozkładu a potem przemnożyć według obecnego rozkładu\n",
        "\n",
        "\n",
        "- discounting\n",
        "Coś takiego teraz kminiłem. Można powiedzieć, że adaptywnie się dopasowuje do poziomu uzytkownika: Do rozkminienia\n",
        "Input:  lista tematów L, discounted historia błędów przypisanych do każdego poziomu ze wszystkich poprzednich rozmów, czyli po rozmowie numer N dla każdego z poziomów mamy := gamma^0 * B_N + gamma^1 * B_{N-1} + gamma^2 * B_{N-2} + ..., gdzie gamma \\in [0,1], a B_i to % tur, w których pojawił się błąd z tego poziomu w rozmowie numer i... Możemy wziąć z tego sigmoid(.) i będziemy meli liczby pomiędzy 0.5 a 1, a potem zamienić na rozkład prawdopodobieństwa? No i możemy wybrać wprost proporcjonalnie do tych wartości, tzn. losowy temat z poziomu wybranego według tego rozkładu co stworzyliśmy.\n",
        "\n",
        "\n",
        "- a jak chcielismy liczyć te błędy, w sensie jak reprezentować?\n",
        "jak wektor 6 elementowy?\n",
        "i suma błędów z każdego poziomu w wektorze?\n",
        "co można zamienić na rozkład i przemnożyć przez obecny rozkład i dostaniemy rozkład poziomów?\n",
        "można też jak mówiłeś włożyć do wektora błędów błędy z ostatnih 20 rozmów\n",
        "albo wszystkie tylko sumować z tą temperaturą gamma w zależności od tego jak dawno była rozmowa\n",
        "potem i tak zamiana wektora na rozkład i przemnożenie przez obecny\n",
        "\n",
        "- niech będzie z parametrem gamma temperatura/discounting dla błędów z każdej historycznej rozmowy.\n",
        "czyli input  = [[wektor błędów na każdym poziomie w ostatniej rozmowie], [przdostatniej rozmowie, ..., [pierwszejrozmowie]], [rozkład poziomów], gamma\n",
        "zamieniamy to na wektor [B_A1_1 + B_A1_2*gamma + B_A1_3*gamma^2 + ..., B_A2_1 + B_A2_2*gamma + ..., ...,B_C2_1 + B_C2_2 * gamma + ...]\n",
        "zamieniamy to na rozkład R\n",
        "output = R * [rozkład poziomów]\n",
        "[wektor błędów na każdym poziomie w rozmowie i] = [X1, X2, X3, X4, X5, X6], gdzie Xi \\in N (a nawet są jeszcze bardziej ograniczone)\n",
        "gamma \\in [0,1]\n",
        "[rozkład poziomów] = [P1, P2, P3, P4, P5, P6] t.że Pi \\in [0,1] AND SUM_i Pi = 1\n",
        "\n",
        "- można ten algorytm napisać taki w teorii, że niby pamięta całość. A formalnie zapamiętamy 20 rozmów np.\n",
        "ja juz muszę lecieć, w każdym razie połączyłbym Twój i mój pomysł... mnożenie rozkładów obecny * wyliczony z historii błędów może być kiedy jekaś gałąź ifa zadziała. A jak popełniasz mniej błędów niż te powiedzmy 10, które dałeś jako wartość progową\n",
        "w sensie gałąź ifa, że popełniłęś więcej niż ta wartość progowa\n",
        "a jak mniej...\n",
        "to może być i ręcznie, bo tam jest mało opcji\n"
      ],
      "metadata": {
        "id": "h-hEVoAd1lY-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jdWv2VlL8Yp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Equitable distribution means everyone gets their fair share of something. If you work on a group project in class, you want an equitable share of the credit. When you look at equitable, you might think you see the word, equal, but it doesn't mean fair in the sense of exactly the same."
      ],
      "metadata": {
        "id": "E4YXmr4GXI6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorytm 1"
      ],
      "metadata": {
        "id": "z1Xtj8M_Eyin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def update_probability_distribution(probabilities, N):\n",
        "    # Convert the probabilities to decimal form.\n",
        "    probabilities = [float(i) / 100 for i in probabilities]\n",
        "\n",
        "\n",
        "    # Determine the maximum value and its index.\n",
        "    max_value = max(probabilities)\n",
        "    max_index = probabilities.index(max_value)\n",
        "\n",
        "\n",
        "    # Decrease the maximum value by an amount proportional to N.\n",
        "    decrease = max_value * abs(N) / 100\n",
        "    probabilities[max_index] -= decrease\n",
        "\n",
        "    # Determine the total of the non-maximum values.\n",
        "    non_max_total = sum(probabilities[i] for i in range(len(probabilities)) if i != max_index)\n",
        "\n",
        "    # Distribute the decrease among the non-maximum values proportionally.\n",
        "    for i in range(len(probabilities)):\n",
        "        if i == max_index:\n",
        "            continue\n",
        "        probabilities[i] += decrease * (probabilities[i] / non_max_total)\n",
        "\n",
        "\n",
        "    # Convert the probabilities back to percentage form.\n",
        "    return [round(i * 100, 2) for i in probabilities]\n",
        "\n",
        "# w momencie gdy user jest na poziomie b2 w dół może zejśc tylko 3 razy - musimy wtedy\n",
        "# aktualizować listę poziomów - sumować poziomy brakujące --> rozdzielać proporcjonalnie wsród pozostałych\n",
        "# moze daloby sei tak zeby po prsotu blad na poziomie a1 mial wieksza wage niz blad na poziomie c2?\n",
        "\n",
        "probabilities = [60, 20, 10, 6, 3, 1]\n",
        "\n",
        "for N in range(-1, -51, -1):\n",
        "    print(f\"N = {N}: {update_probability_distribution(probabilities, N)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4grDyT0fnBV3",
        "outputId": "6c2391b5-0ab4-40e6-8d78-d4d9074bbfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = -1: [59.4, 20.3, 10.15, 6.09, 3.04, 1.02]\n",
            "N = -2: [58.8, 20.6, 10.3, 6.18, 3.09, 1.03]\n",
            "N = -3: [58.2, 20.9, 10.45, 6.27, 3.13, 1.05]\n",
            "N = -4: [57.6, 21.2, 10.6, 6.36, 3.18, 1.06]\n",
            "N = -5: [57.0, 21.5, 10.75, 6.45, 3.23, 1.08]\n",
            "N = -6: [56.4, 21.8, 10.9, 6.54, 3.27, 1.09]\n",
            "N = -7: [55.8, 22.1, 11.05, 6.63, 3.31, 1.1]\n",
            "N = -8: [55.2, 22.4, 11.2, 6.72, 3.36, 1.12]\n",
            "N = -9: [54.6, 22.7, 11.35, 6.81, 3.4, 1.13]\n",
            "N = -10: [54.0, 23.0, 11.5, 6.9, 3.45, 1.15]\n",
            "N = -11: [53.4, 23.3, 11.65, 6.99, 3.5, 1.17]\n",
            "N = -12: [52.8, 23.6, 11.8, 7.08, 3.54, 1.18]\n",
            "N = -13: [52.2, 23.9, 11.95, 7.17, 3.58, 1.2]\n",
            "N = -14: [51.6, 24.2, 12.1, 7.26, 3.63, 1.21]\n",
            "N = -15: [51.0, 24.5, 12.25, 7.35, 3.67, 1.23]\n",
            "N = -16: [50.4, 24.8, 12.4, 7.44, 3.72, 1.24]\n",
            "N = -17: [49.8, 25.1, 12.55, 7.53, 3.76, 1.26]\n",
            "N = -18: [49.2, 25.4, 12.7, 7.62, 3.81, 1.27]\n",
            "N = -19: [48.6, 25.7, 12.85, 7.71, 3.85, 1.29]\n",
            "N = -20: [48.0, 26.0, 13.0, 7.8, 3.9, 1.3]\n",
            "N = -21: [47.4, 26.3, 13.15, 7.89, 3.94, 1.31]\n",
            "N = -22: [46.8, 26.6, 13.3, 7.98, 3.99, 1.33]\n",
            "N = -23: [46.2, 26.9, 13.45, 8.07, 4.04, 1.34]\n",
            "N = -24: [45.6, 27.2, 13.6, 8.16, 4.08, 1.36]\n",
            "N = -25: [45.0, 27.5, 13.75, 8.25, 4.12, 1.38]\n",
            "N = -26: [44.4, 27.8, 13.9, 8.34, 4.17, 1.39]\n",
            "N = -27: [43.8, 28.1, 14.05, 8.43, 4.21, 1.41]\n",
            "N = -28: [43.2, 28.4, 14.2, 8.52, 4.26, 1.42]\n",
            "N = -29: [42.6, 28.7, 14.35, 8.61, 4.3, 1.44]\n",
            "N = -30: [42.0, 29.0, 14.5, 8.7, 4.35, 1.45]\n",
            "N = -31: [41.4, 29.3, 14.65, 8.79, 4.39, 1.47]\n",
            "N = -32: [40.8, 29.6, 14.8, 8.88, 4.44, 1.48]\n",
            "N = -33: [40.2, 29.9, 14.95, 8.97, 4.49, 1.49]\n",
            "N = -34: [39.6, 30.2, 15.1, 9.06, 4.53, 1.51]\n",
            "N = -35: [39.0, 30.5, 15.25, 9.15, 4.58, 1.52]\n",
            "N = -36: [38.4, 30.8, 15.4, 9.24, 4.62, 1.54]\n",
            "N = -37: [37.8, 31.1, 15.55, 9.33, 4.67, 1.55]\n",
            "N = -38: [37.2, 31.4, 15.7, 9.42, 4.71, 1.57]\n",
            "N = -39: [36.6, 31.7, 15.85, 9.51, 4.75, 1.58]\n",
            "N = -40: [36.0, 32.0, 16.0, 9.6, 4.8, 1.6]\n",
            "N = -41: [35.4, 32.3, 16.15, 9.69, 4.84, 1.61]\n",
            "N = -42: [34.8, 32.6, 16.3, 9.78, 4.89, 1.63]\n",
            "N = -43: [34.2, 32.9, 16.45, 9.87, 4.93, 1.65]\n",
            "N = -44: [33.6, 33.2, 16.6, 9.96, 4.98, 1.66]\n",
            "N = -45: [33.0, 33.5, 16.75, 10.05, 5.03, 1.68]\n",
            "N = -46: [32.4, 33.8, 16.9, 10.14, 5.07, 1.69]\n",
            "N = -47: [31.8, 34.1, 17.05, 10.23, 5.12, 1.7]\n",
            "N = -48: [31.2, 34.4, 17.2, 10.32, 5.16, 1.72]\n",
            "N = -49: [30.6, 34.7, 17.35, 10.41, 5.21, 1.73]\n",
            "N = -50: [30.0, 35.0, 17.5, 10.5, 5.25, 1.75]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Dokumentacja:\n",
        "\n",
        "```python\n",
        "def aktualizuj_rozklad_prawdopodobienstwa(prawdopodobienstwa, N):\n",
        "    \"\"\"\n",
        "    Funkcja modyfikująca rozkład prawdopodobieństwa na podstawie danego parametru, N.\n",
        "\n",
        "    Parametry:\n",
        "    prawdopodobienstwa (Lista int): Lista wartości prawdopodobieństwa przy N = 0.\n",
        "                                    Każda wartość powinna być w zakresie [0, 100].\n",
        "                                    Suma wartości musi wynosić 100.\n",
        "                                    Na przykład: [60, 20, 10, 6, 3, 1].\n",
        "    \n",
        "    N (int):                       Parametr kontrolny modyfikacji.\n",
        "                                    Powinien być ujemny. Im jest bardziej ujemny,\n",
        "                                    tym większe jest zmniejszenie maksymalnego prawdopodobieństwa\n",
        "                                    i tym większe jest odpowiadające temu zwiększenie innych prawdopodobieństw.\n",
        "\n",
        "    Zwraca:\n",
        "    Listę float: nowy rozkład prawdopodobieństwa po modyfikacji.\n",
        "\n",
        "    Przykład:\n",
        "\n",
        "    >>> aktualizuj_rozklad_prawdopodobienstwa([60, 20, 10, 6, 3, 1], -1)\n",
        "    [58.0, 20.8, 10.4, 6.25, 3.13, 1.04]\n",
        "    \"\"\"\n",
        "\n",
        "    # Przekształcanie podanych prawdopodobienstw na formę dziesiętną.\n",
        "    prawdopodobienstwa = [float(i) / 100 for i in prawdopodobienstwa]\n",
        "\n",
        "    # Znajdź indeks i wartość maksymalnego prawdopodobieństwa.\n",
        "    max_wartosc = max(prawdopodobienstwa)\n",
        "    max_indeks = prawdopodobienstwa.index(max_wartosc)\n",
        "\n",
        "    # Zmniejszanie maksymalnej wartości proporcjonalnie do N.\n",
        "    spadek = max_wartosc * abs(N) / 100\n",
        "    prawdopodobienstwa[max_indeks] -= spadek\n",
        "\n",
        "    # Oblicza całkowitą pozostałą sumę prawdopodobieństw.\n",
        "    non_max_total = sum(prawdopodobienstwa[i] for i in range(len(prawdopodobienstwa)) if i != max_indeks)\n",
        "\n",
        "    # Rozdzielanie odjętego maksimum po pozostałych prawdopodobieństwach, proporcjonalnie do ich wielkości.\n",
        "    for i in range(len(prawdopodobienstwa)):\n",
        "        if i != max_indeks:\n",
        "            prawdopodobienstwa[i] += spadek * (prawdopodobienstwa[i] / non_max_total)\n",
        "\n",
        "    # Przekształcanie prawdopodobieństw z powrotem na formę procentową do zwrócenia.\n",
        "    return [round(i * 100, 2) for i in prawdopodobienstwa]\n",
        "```"
      ],
      "metadata": {
        "id": "fmhMcrLr2nqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OSTATNIE CHATY\n",
        "\n",
        "\n",
        "\n",
        "I mean i have probability distribution of 6 values. Those values are set to default, when N = 0. N Can be only a negative value. I need this distribution to be updated if N will goes down proportionally. So if N = 0, my probability distribution is  [ 60%, 20%, 10%, 6%, 3%, 1%]. When N goes down, lower values need to increaseproportionally   at the expense of the highest value to N. If N = -1, changes will be small - for example [58%, 21%,10.5%, 6,3%, 3,2%, 1,1%] If N = -30 changes will be much bigger proportionally.\n",
        "\n",
        "\n",
        "Understood. Here's how we can modify the distribution:\n",
        "\n",
        "- Decrease the highest value by an amount proportional to N. This can be achieved by multiplying the highest value with the absolute value of N divided by some number, say 100.\n",
        "- Distribute the decrease in the highest value among the rest of the values. The amount added to each of the other values should be proportional to the value itself, so that smaller values increase by a smaller amount and larger values increase by a larger amount. This can be achieved by first calculating the total of the non-maximum values, determining the proportion of each non-maximum value to this total, and then distributing the decrease in the maximum value according to these proportions.\n",
        "\n",
        "Here's the Python code that implements this:\n",
        "\n",
        "```python\n",
        "def update_probability_distribution(probabilities, N):\n",
        "    # Convert the probabilities to decimal form.\n",
        "    probabilities = [float(i) / 100 for i in probabilities]\n",
        "\n",
        "    # Determine the maximum value and its index.\n",
        "    max_value = max(probabilities)\n",
        "    max_index = probabilities.index(max_value)\n",
        "\n",
        "    # Decrease the maximum value by an amount proportional to N.\n",
        "    decrease = max_value * abs(N) / 100\n",
        "    probabilities[max_index] -= decrease\n",
        "\n",
        "    # Determine the total of the non-maximum values.\n",
        "    non_max_total = sum(probabilities[i] for i in range(len(probabilities)) if i != max_index)\n",
        "\n",
        "    # Distribute the decrease among the non-maximum values proportionally.\n",
        "    for i in range(len(probabilities)):\n",
        "        if i == max_index:\n",
        "            continue\n",
        "        probabilities[i] += decrease * (probabilities[i] / non_max_total)\n",
        "\n",
        "    # Convert the probabilities back to percentage form.\n",
        "    return [round(i * 100, 2) for i in probabilities]\n",
        "\n",
        "probabilities = [60, 20, 10, 6, 3, 1]\n",
        "N = -1\n",
        "print(update_probability_distribution(probabilities, N))\n",
        "N = -30\n",
        "print(update_probability_distribution(probabilities, N))\n",
        "```\n",
        "\n",
        "In this code, `decrease` represents the amount subtracted from the maximum value, and `decrease * (probabilities[i] / non_max_total)` is the amount added to each non-maximum value. The absolute value of N is used to ensure that the distribution is updated correctly whether N is negative or positive. The code divides N by 100 to reduce its impact on the update - you can adjust this divisor to change how much N affects the update."
      ],
      "metadata": {
        "id": "XWFVe_Fcvju_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rozkład gaussowski"
      ],
      "metadata": {
        "id": "rdzGVpyXAMrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Ustalamy seed dla powtarzalności\n",
        "np.random.seed(0)\n",
        "\n",
        "# prawdziwe parametry rozkładu\n",
        "true_mean = 4\n",
        "true_std = 9\n",
        "\n",
        "# generujemy dane\n",
        "data = np.random.normal(true_mean, true_std, 1000)\n",
        "\n",
        "# estymujemy parametry za pomocą MLE\n",
        "estimated_mean, estimated_std = norm.fit(data)\n",
        "\n",
        "print(f\"Prawdziwe parametry: średnia = {true_mean}, odchylenie standardowe = {true_std}\")\n",
        "print(f\"Oszacowane parametry: średnia = {estimated_mean}, odchylenie standardowe = {estimated_std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqMpC2AeAwi5",
        "outputId": "2bc77146-eeaf-4e00-df14-ac7401bcd3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prawdziwe parametry: średnia = 4, odchylenie standardowe = 9\n",
            "Oszacowane parametry: średnia = 3.592689632588242, odchylenie standardowe = 8.883298428021233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metoda gradientowa\n",
        "\n",
        "Zastanów się czy można metodą schodzenia po gradiencie, gdzie gradientem jest np średnia (może być ważona) błędów z każdego poziomu w ostatnich no 10 rozmowach https://en.m.wikipedia.org/wiki/Gradient_descent\n",
        "Nie ma funkcji celu nadal wiem…\n",
        "\n",
        "Może da się jakąś wyznaczyć\n",
        "Może bez sensu. Można wziąć tą średnią z błędów na każdym poziomie i wyliczyć z tego rozkład procentowy i połączyć z wyjściowym rozkładem dla poziomów\n",
        "\n",
        "\n",
        "\n",
        "- w sytuacji kiedy uzytkownik jest na b1 i dostanie szanse jedna/dwie na poziom wyżej - a nastepnie bedzie miał tam dużo błędów - to system bęzdie omijał już te poziomy bez mozliwosci dania uzytkonikowi kolejnej szansy\n",
        "\n",
        "\n",
        "\n",
        "JESTEM NA B1\n",
        "\n",
        "ostatnie 20 rund z tych poziomów:\n",
        "\n",
        "na a1 srednia: 1\n",
        "na a2 srednia:2\n",
        "na b1 srednia 5\n",
        "na b2 srednia 3\n",
        "na c1 srednia 10\n",
        "na c2 srednia 2\n",
        "\n",
        "\n",
        "jaki powninen być zwiazek tych błędów z prawdopodobienstwem nastepnego poziomu?\n",
        "\n"
      ],
      "metadata": {
        "id": "0FUDxTvXNSA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorytm 2\n",
        "\n",
        "\n",
        "### wszystke dane\n",
        "\n",
        "- Domyślna wartość będzie definiować wartość suma temperatur z kazdego z poziomów\n",
        "ponizej bedziemy stosować algorytm oraz powyzej\n",
        "\n",
        "Wektory Błędów\n",
        "\n",
        "\n",
        "- moze warto rozroznic temperature kazdego z poziomow oraz temperature ogolna wszystkich bledow? jesli temperatura ogolna niska to spoko - prwdp wyzsych poziomow rosnie. konfrontacja tempratur z kazdego poziomu a ogolnej - co da? bedzie sprawiedliwiej\n",
        "\n",
        "- temperatura gamma ma rosnac gdy poziom byl dawno oraz gdy bledow jest mało\n",
        "czyli warunek pradopodobienstwa(temperatura, błędy), musi wplywac na wyznaczony wczesniej - domyślnu układ prawdopodobieństwa\n",
        "\n",
        "\n",
        "PRZYKŁAD WYGLĄDU WEKTORÓW BŁĘDÓW - Wartosci 0 = bezbłędny case lub brak case na danym poziomie w aktualnej rundzie. Każdy z wektorów aktualizuje się co rundę\n",
        "\n",
        "- A1 = [1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0]\n",
        "- A2 = [0,0, 0,0,0,0,0,0,2,0,3,0,0,0,0]\n",
        "- B1 = [0,0, 4,0,0,1,0,0,0,2,0,1,0,0,0]\n",
        "- B2 = [0,0, 0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "- C1 = [0,0, 0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "- C2 = [0,10,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "\n",
        "- Wektor_wszystkich błędów = wartosci dawniejsze powinny miec mniejszy wplyw, wartosci z wyzszych poziomów powinny mieć mniejszy wplyw. Jesli wartosc na danym poziomie uztywkonika lub nizszym jest wysoka = rosnie prawdpopodobienstwo cofniecia. Cos jak taki licznik - a1 na 70%  = warto uzytkownika Cofać aż temperatura nie zmaleje - nie bedzie blizsza 0. Jeśli ogólna temperatura błędów będzie blisko 0 = wieksza szansa na trafienie poziomu wyżej - a co za tym idzie mozliwosc szybszego wbijania expa lub jakichś odznak\n",
        "\n",
        "\n",
        "KRÓL_WEKTOR = [A1: temperatura_wektora, A2: temperatura_wektora, B1: temperatura_wektora , B2: temperatura_wektora, C1: temperatura_wektora, C2: temperatura_wektora]\n",
        "\n",
        "### Plan Algorytmu 2\n",
        "\n",
        "1. 6 wektorów błędów z 20 poziomów\n",
        "\n",
        "2. kod segregujacy poziomy zaleznie od aktualnego poziomu uzytkownika( aby dostosować wartość gama - nasz mnożnik)\n",
        "\n",
        "3. wyciagamy temperature z każdego z poziomów za pomocą wzoru : [B_A1_1 + B_A1_2*gamma + B_A1_3*gamma^2 + ..., B_A2_1 + B_A2_2*gamma + ..., ...,B_C2_1 + B_C2_2 * gamma + ...]\n",
        "\n",
        "4. Sumujemy raz normalizujemy wynik - wartość od 0 do około - 100 / może sprówobwac wyniki dać do jednego wektora a następnie zamienić na rozkład prawdopodobieństwa\n",
        "\n",
        "5. Wciagamy do Algorytmu #1\n",
        "\n",
        "\n",
        "POV: Jestes na B2 chujowo ci idzie spadasz nizej --> na nizszych idzie ci tez slabo --> dopoki nie ogarniesz pzoiomow nizej nie ma szans wejsc na poziomy wyzej\n",
        "\n",
        "\n",
        "- Jak nasz algorytm powinien sie zachowywac? patrzec powinien tylko w tył? jesli temperatura poziomów >= aktualnego poziomu jest bliska 0 --> rosnie prawdopodobienstwo wrzucenia uzytkownika wyzej\n",
        "\n",
        "NIE KONIECZNIE - mnozniki bledow poziomow wyzej moga byc minimalne\n",
        "\n",
        "- Czyli osoba na B2 dobrze radzaca sobie na tych poziomach dostaje wiecej szans na c1 oraz troche na c2 ---> dzieki czemu dostaje wiecej expa\n",
        "\n",
        "### kwestia expa\n",
        "\n",
        "- odpowiadanie na poziomach nizszych niz jest uzytkownik = mniej expa / wyższych = wiecej expa\n",
        "\n",
        "### Kwestia mnoznikow\n",
        "\n",
        "nie powinny byc jakies mocne - na c2 zeby blad a1 nie mial mnoznika 10\n",
        "\n",
        "#### N\n",
        "\n",
        "- Powinnismy znalezc wartosc N ktora nam bezdie mowic jak mocno zwiekszyc rozklad prawdopodobientwa z algorytmu 1\n",
        "\n",
        "- Moz po prsotu kurwa sumujmy z mnoznikami wartosci dla poziomow temperatury --> znormalizujmy to ( zakres 0-100 np) no i mamy N :))  ----> mozemy polaczyc z algorytmem #1\n",
        "\n",
        "\n",
        "WZORY:\n",
        "\n",
        "- gamma^0 * B_N + gamma^1 * B_{N-1} + gamma^2 * B_{N-2} + ...,\n",
        "\n",
        "- [B_A1_1 + B_A1_2*gamma + B_A1_3*gamma^2 + ..., B_A2_1 + B_A2_2*gamma + ..., ...,B_C2_1 + B_C2_2 * gamma + ...]\n",
        "\n",
        "- musimy osobno liczyc dla kazdego z poziomow zeby moc je rozrozniac i dawac mnozniki\n",
        "\n",
        "- input  = [[wektor błędów na każdym poziomie w ostatniej rozmowie], [przdostatniej rozmowie, ..., [pierwszejrozmowie]], [rozkład poziomów],\n"
      ],
      "metadata": {
        "id": "lYQLVgQ0RJm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTY WZORÓW\n",
        "\n",
        "\n",
        "# Przykładowa wartość gamma.\n",
        "gamma = 0.9\n",
        "\n",
        "# Przykładowa lista składników B_A1.\n",
        "B_A1 = [1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "# Inicjalizacja wartości wyniku.\n",
        "result = 0\n",
        "\n",
        "# Pętla po składnikach B_A1\n",
        "for i in range(len(B_A1)):\n",
        "    result += B_A1[i] * (gamma ** i)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd4PsZNPNY6Y",
        "outputId": "4faa9f7a-0807-4daf-b87d-94a38e3469fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7904969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_discounted_sum(Wektor_błędów, gamma):\n",
        "    \"\"\"\n",
        "    Funkcja obliczająca temperaturę każdegoz  wektorów błędów.\n",
        "\n",
        "    Użyty wzór : - [B_A1_1 + B_A1_2*gamma + B_A1_3*gamma^2 + ..., B_A2_1 + B_A2_2*gamma + ..., ...,B_C2_1 + B_C2_2 * gamma + ...]\n",
        "\n",
        "    Parametry:\n",
        "    Wektor_błędów (list of floats/int): Lista składników (przewidywanych nagród).\n",
        "    gamma (float): Współczynnik dyskontujący, powinien leżeć w przedziale [0, 1] lub w sumie nie\n",
        "\n",
        "    Zwraca:\n",
        "    float: Sumę przewidywanych nagród.\n",
        "\n",
        "    Przykład:\n",
        "    >>> calculate_discounted_sum([1, 2, 3, 4, 5], 0.9)\n",
        "    3.439\n",
        "    \"\"\"\n",
        "    result = 0\n",
        "    for i in range(len(Wektor_błędów)):\n",
        "        result += Wektor_błędów[i] * (gamma ** i)\n",
        "    return round(result, 3)\n",
        "\n",
        "\n",
        "\n",
        "a1 = ('A1: ', calculate_discounted_sum([1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0], 0.9))\n",
        "\n",
        "\n",
        "print(a1)\n",
        "\n",
        "a2 = ('A2: ', calculate_discounted_sum([1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0], 0.8))\n",
        "\n",
        "print(a2)\n",
        "b1 = ('B1: ', calculate_discounted_sum([1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0], 0.7))\n",
        "\n",
        "print(b1)\n",
        "b2 = ('B2: ', calculate_discounted_sum([1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0], 0.6))\n",
        "\n",
        "print(b2)\n",
        "c1 = ('C1: ', calculate_discounted_sum([1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0], 0.5))\n",
        "\n",
        "print(c1)\n",
        "c2 = ('C2: ', calculate_discounted_sum([1,0, 0,0,2,0,0,1,0,0,0,0,0,0,0], 0.2))\n",
        "\n",
        "print(c2)\n",
        "\n",
        "\n",
        "# Wartość gamma jest aktualnie ustawiana ręcznie ->\n",
        "# potrzeba kodu automatyzującego - uzytkownik na a2 --> dostosowanie sie mnozników do jego pozycji\n",
        "\n",
        "# jak znormalizować wartość końcową?\n",
        "\n",
        "# może zrobić z wektora głównego rozkład prawdopodonieństwa? - stracimy troche na elastyczności wtedy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVkllomrOCDi",
        "outputId": "6245eb8f-be3a-4092-f6cd-247abbde70d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('A1: ', 2.79)\n",
            "('A2: ', 2.029)\n",
            "('B1: ', 1.563)\n",
            "('B2: ', 1.287)\n",
            "('C1: ', 1.133)\n",
            "('C2: ', 1.003)\n"
          ]
        }
      ]
    }
  ]
}