{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vidayERjaO5q"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "some kinds of time series:\n",
        "- trend(upward forexample)\n",
        "- seasonality ( peaks szczyty , troughs do≈Çy)\n",
        "- both of them\n",
        "- white noise\n",
        "\n",
        "\n",
        "Since neural networks rely on stochasticity (i.e. randomness) to initialize their parameters and gradient descent selects random batches of training data at each iteration, is perfectly normal if the outputs you see when you run the Colabs are slightly different from those shown in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqWabzlJ63nL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJwA96JU00pW"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
        "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    if label:\n",
        "        plt.legend(fontsize=14)\n",
        "    plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVo6CcpRaW7u"
      },
      "source": [
        "## Trend and Seasonality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t30Ts2KjiOIY"
      },
      "outputs": [],
      "source": [
        "def trend(time, slope=0):\n",
        "    return slope * time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJjc3G1Maefn"
      },
      "source": [
        "Let's create a time series that just trends upward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLt-pLiZ0nfB"
      },
      "outputs": [],
      "source": [
        "time = np.arange(4 * 365 + 1)\n",
        "baseline = 10\n",
        "series = baseline + trend(time, 0.1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-4hV2WHTC_F"
      },
      "outputs": [],
      "source": [
        "time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOK7NnaOTGa7"
      },
      "outputs": [],
      "source": [
        "series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKD4nh9sauBf"
      },
      "source": [
        "Now let's generate a time series with a seasonal pattern:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89gdEnPY1Niy"
      },
      "outputs": [],
      "source": [
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kaNezUk1S9l"
      },
      "outputs": [],
      "source": [
        "amplitude = 40\n",
        "series = seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vo433h0bDLD"
      },
      "source": [
        "Now let's create a time series with both trend and seasonality:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyqFdaIN1oy5"
      },
      "outputs": [],
      "source": [
        "slope = 0.05\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVdJ2jNN8OHk"
      },
      "source": [
        "## Noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4taP424sces"
      },
      "source": [
        "In practice few real-life time series have such a smooth signal. They usually have some noise, and the signal-to-noise ratio can sometimes be very low. Let's generate some white noise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kD3_zjVscBH"
      },
      "outputs": [],
      "source": [
        "def white_noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLvBwrKrtDzo"
      },
      "outputs": [],
      "source": [
        "noise_level = 5\n",
        "noise = white_noise(time, noise_level, seed=42)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, noise)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHa6gicgbL74"
      },
      "source": [
        "Now let's add this white noise to the time series:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bRDx8K816N9"
      },
      "outputs": [],
      "source": [
        "series += noise\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fixed Partitioning:\n",
        "\n",
        "\n",
        "- 3 parts - train validation test \n",
        "- discover seasonality - years second weeks\n",
        "\n",
        "\n",
        "\n",
        "https://learn.udacity.com/courses/ud187/lessons/19212c74-9f30-459c-aa74-4d10abdcff23/concepts/58c32cf3-6778-4393-a2ed-a15507206fc8 \n",
        "\n",
        "# Roll-Forward Partitioning\n",
        "\n",
        "\n",
        "\n",
        "# Naive_Forecasting\n",
        "\n",
        "https://learn.udacity.com/courses/ud187/lessons/19212c74-9f30-459c-aa74-4d10abdcff23/concepts/bf69efd4-ca86-4691-b42e-a60277a81a96\n",
        "\n",
        "https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c02_naive_forecasting.ipynb\n",
        "\n",
        "\n",
        "\n",
        "# metrics\n",
        "\n",
        "\n",
        "\n",
        "errors = forecast - actual\n",
        "\n",
        "mse = np.square(errors).mean()\n",
        "\n",
        "rmse = pierwiastek z mse\n",
        "\n",
        "mae = np.abs(errors).mean()\n",
        "\n",
        "mape = np.abs(errors / x_valid).mean() ( mean ratio between the absolute error and absolute value)\n",
        "\n",
        "\n",
        "\n",
        "### measuring \n",
        "\n",
        "    keras.metrics.mean_absolute_error(x_valid, naive_forecst).numpy()\n",
        "\n",
        "\n",
        "# moving AVERAGE \n",
        "\n",
        "\n",
        "mean of the past N values\n",
        "\n",
        "nice;y eliminate a lofof noise\n",
        "\n",
        "not anticipate seasonality and trend\n",
        "\n",
        "\n",
        "\n",
        "# differencing\n",
        "\n",
        "\n",
        "\n",
        "study the difference between the value at time t and the value one year earlier = time t - 365\n",
        "\n",
        "we get this differenced time series which has no trend and no seasonality\n",
        "\n",
        "than we can apply moving average\n",
        "\n",
        "To the final forecast we need to add back the value at time t minus 365\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- https://learn.udacity.com/courses/ud187/lessons/19212c74-9f30-459c-aa74-4d10abdcff23/concepts/9b131231-1b05-4e11-8ad0-1992a7c01ae6\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "but the forecast is still noisy \n",
        "we need to improve that by also removing the past noise using the moving average\n",
        "\n",
        "\n",
        "\n",
        "- optimal MAE +- 4.0\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "time window  = for example week moth or somethin\n",
        "\n",
        "forecast - prognoza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-15 01:35:32.851468: W tensorflow/core/framework/dataset.cc:769] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "2022-12-15 01:35:32.868974: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n",
            "2022-12-15 01:35:32.872792: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n",
            "2022-12-15 01:35:32.876288: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n",
            "2022-12-15 01:35:32.879303: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n",
            "2022-12-15 01:35:32.882191: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5,shift=1, drop_remainder=True)\n",
        "\n",
        "\n",
        "for window_dataset in dataset:\n",
        "\n",
        "    for val in window_dataset:\n",
        "        print(val.numpy(), end = ' ')\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[1 2 3 4 5]\n",
            "[2 3 4 5 6]\n",
            "[3 4 5 6 7]\n",
            "[4 5 6 7 8]\n",
            "[5 6 7 8 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-15 01:35:46.995100: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5,shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "\n",
        "\n",
        "for window in dataset:\n",
        "\n",
        "    print(window.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3382988835.py, line 9)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_22114/3382988835.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    dataset = dataset.map(lambda window:(window:[:-1],window[-1:]))\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5,shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window:(window:[:-1],window[-1:]))\n",
        "\n",
        "for x,y in dataset:\n",
        "\n",
        "    print(x.numpy(), y.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3] [4]\n",
            "[1 2 3 4] [5]\n",
            "[2 3 4 5] [6]\n",
            "[3 4 5 6] [7]\n",
            "[4 5 6 7] [8]\n",
            "[5 6 7 8] [9]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5,shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window:(window[:-1], window[-1:]))\n",
        "\n",
        "for x,y in dataset:\n",
        "\n",
        "    print(x.numpy(), y.numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "shuffling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2 3 4 5] [6]\n",
            "[4 5 6 7] [8]\n",
            "[1 2 3 4] [5]\n",
            "[0 1 2 3] [4]\n",
            "[3 4 5 6] [7]\n",
            "[5 6 7 8] [9]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5,shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window:(window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "\n",
        "\n",
        "for x,y in dataset:\n",
        "\n",
        "    print(x.numpy(), y.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = [[1 2 3 4]\n",
            " [5 6 7 8]] [[1 2 3 4]\n",
            " [5 6 7 8]]\n",
            "y = [[1 2 3 4]\n",
            " [5 6 7 8]] [[5]\n",
            " [9]]\n",
            "x = [[2 3 4 5]\n",
            " [3 4 5 6]] [[2 3 4 5]\n",
            " [3 4 5 6]]\n",
            "y = [[2 3 4 5]\n",
            " [3 4 5 6]] [[6]\n",
            " [7]]\n",
            "x = [[0 1 2 3]\n",
            " [4 5 6 7]] [[0 1 2 3]\n",
            " [4 5 6 7]]\n",
            "y = [[0 1 2 3]\n",
            " [4 5 6 7]] [[4]\n",
            " [8]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5,shift=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "dataset = dataset.map(lambda window:(window[:-1], window[-1:]))\n",
        "dataset = dataset.shuffle(buffer_size=10)\n",
        "dataset = dataset.batch(2).prefetch(1)\n",
        "\n",
        "\n",
        "for x,y in dataset:\n",
        "\n",
        "    print('x =' , x.numpy(), x.numpy())\n",
        "    print('y =' , x.numpy(), y.numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def window_dataset(series , window_size, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1,shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.map(lambda w:(w[:-1], [-1]))\n",
        "    ds = ds.shuffle(len(series))\n",
        "    ds = ds.batch(batch_size).prefetch(1)\n",
        "\n",
        "# convet time series into a data set that we can use to train the machine learning model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c04_time_windows.ipynb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "huber losses = quadratic for small errors just like the mean squared loss\n",
        "            linear for large errors just like the mean absolute error\n",
        "            "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# forecasting with ML models\n",
        "\n",
        "In progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RNNs\n",
        "\n",
        "\n",
        "in progress"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "l08c01_common_patterns.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
